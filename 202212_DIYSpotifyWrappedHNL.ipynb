{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Spotify Wrapped 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyClientCredentials \n",
    "from tqdm import tqdm_notebook\n",
    "import requests\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connect to Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate token\n",
    "username = '{insert_your_username}'\n",
    "client_id = '{insert_client_id}'\n",
    "client_secret = '{insert_client_secret}'\n",
    "\n",
    "client_credentials = SpotifyClientCredentials(client_id, client_secret)\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to convert json files of streaming histories into a single dataframe\n",
    "def get_streaming_hist_raw(json_file_list):\n",
    "    result_df = pd.DataFrame()\n",
    "    for json_file in json_file_list:\n",
    "        # Open json file\n",
    "        with open(json_file) as streaming_history_json:\n",
    "            streaming_history_string = json.load(streaming_history_json)\n",
    "        \n",
    "        # Convert json file into dataframe\n",
    "        streaming_history_df = pd.json_normalize(streaming_history_string)\n",
    "        \n",
    "        # Append to the combined dataframe\n",
    "        result_df = pd.concat([result_df, streaming_history_df])\n",
    "        \n",
    "    # After all json have been added to the dataframe, drop duplicates\n",
    "    result_df = result_df.drop_duplicates()\n",
    "    result_df = result_df.rename(columns={'master_metadata_track_name':'trackName', 'master_metadata_album_artist_name':'artistName', 'master_metadata_album_album_name':'albumName'})\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get streaming history dataframe\n",
    "json_file_list = ['endsong_0.json', 'endsong_1.json', 'endsong_2.json', 'endsong_3.json', 'endsong_4.json', 'endsong_5.json', 'endsong_6.json', 'endsong_7.json', 'endsong_8.json', 'endsong_9.json']\n",
    "streaming_hist_df = get_streaming_hist_raw(json_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_hist_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2. Get track info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to create a dictionary of trackNames and artistNames\n",
    "# This will be an input for later\n",
    "def get_trackName_artistName_dict(df):\n",
    "    # Drop duplicates\n",
    "    unique_artistName_trackName_df = df[['artistName','trackName']].drop_duplicates()\n",
    "    \n",
    "    # Convert df into lists\n",
    "    trackName_list = unique_artistName_trackName_df['trackName'].to_list()\n",
    "    artistName_list = unique_artistName_trackName_df['artistName'].to_list()\n",
    "    \n",
    "    # Create dictionary\n",
    "    trackName_artistName_dict = {}\n",
    "    for trackName in trackName_list:\n",
    "        for artistName in artistName_list:\n",
    "            trackName_artistName_dict[trackName] = artistName\n",
    "            artistName_list.remove(artistName)\n",
    "            break\n",
    "    return trackName_artistName_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get track info\n",
    "def get_track_info(dict):\n",
    "    # Create empty list\n",
    "    track_id_list = []\n",
    "    track_name_list = []\n",
    "    track_popularity_list = []\n",
    "    track_duration_list = []\n",
    "    track_is_local_list = []\n",
    "    artist_id_list = []\n",
    "    artist_name_list = []\n",
    "    album_id_list = []\n",
    "    album_release_date_list = []\n",
    "    \n",
    "    # Declare counter\n",
    "    count = 1\n",
    "    \n",
    "    # Retrieve track info\n",
    "    for trackName, artistName in dict.items():        \n",
    "        try:\n",
    "            json = sp.search(q=f'{trackName} artist: {artistName}', type='track')\n",
    "            track_info_items = json['tracks']['items'][0]\n",
    "            print(f'track {count}: {trackName} - {artistName}... SUCCESSFUL')\n",
    "        except Exception:\n",
    "            try:\n",
    "                json = sp.search(q=f'{trackName}', type='track')\n",
    "                track_info_items = json['tracks']['items'][0]\n",
    "                print(f'track {count}: {trackName} - {artistName}... SUCCESSFUL')\n",
    "            except Exception:\n",
    "                print(f'track {count}: {trackName} - {artistName}... FAILED')\n",
    "                pass\n",
    "        \n",
    "        # Extract info to separate lists\n",
    "        try:\n",
    "            track_id_list.append(track_info_items['id']) # track_id\n",
    "        except Exception:\n",
    "            track_id_list.append('Unidentified')\n",
    "        \n",
    "        try:\n",
    "            track_popularity_list.append(track_info_items['popularity']) # trackPopularity\n",
    "        except Exception:\n",
    "            track_popularity_list.append('Unidentified')\n",
    "            \n",
    "        try:\n",
    "            track_duration_list.append(track_info_items['duration_ms']) # trackDurationMs\n",
    "        except Exception:\n",
    "            track_duration_list.append('Unidentified')\n",
    "        \n",
    "        try:\n",
    "            track_is_local_list.append(track_info_items['is_local']) #trackIsLocal\n",
    "        except Exception:\n",
    "            track_is_local_list.append('Unidentified')\n",
    "            \n",
    "        try:\n",
    "            artist_id_list.append(track_info_items['artists'][0]['id']) # artistId\n",
    "        except Exception:\n",
    "            artist_id_list.append('Unidentified')\n",
    "            \n",
    "        try:\n",
    "            album_id_list.append(track_info_items['album']['id']) #album_id\n",
    "        except Exception:\n",
    "            album_id_list.append('Unidentified')\n",
    "            \n",
    "        try:\n",
    "            album_release_date_list.append(track_info_items['album']['release_date']) #album_release_date\n",
    "        except Exception:\n",
    "            album_release_date_list.append('Unidentified')\n",
    "            \n",
    "        count+=1\n",
    "        \n",
    "    \n",
    "    # Transform lists into a single dataframe\n",
    "    track_name_list = list(dict.keys())\n",
    "    artist_name_list = list(dict.values())\n",
    "    data_tuples = list(zip(track_id_list, track_name_list, track_popularity_list, track_duration_list, track_is_local_list, artist_id_list, artist_name_list, album_id_list, album_release_date_list))\n",
    "    col_names = ['trackId','trackName','trackPopularity','trackDurationMs','trackIsLocal','artistId','artistName','albumId','albumReleaseDate']\n",
    "    df = pd.DataFrame(data_tuples, columns=col_names)\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply the function to create a dictionary of trackNames and artistNames\n",
    "trackName_artistName_dict = get_trackName_artistName_dict(streaming_hist_df)\n",
    "\n",
    "# Apply the function to get track info\n",
    "track_reference_df = get_track_info(trackName_artistName_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.3. Get track's audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get audio features of a single track\n",
    "def get_audio_features(track_id: str) -> dict:\n",
    "    try:\n",
    "        features = sp.audio_features(track_id)\n",
    "        return features[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to populate the audio features of a trackId list\n",
    "def get_audio_features_df(track_id_list: list) -> dict:\n",
    "    # Create empty dictionary\n",
    "    audio_features_dict = {}\n",
    "    \n",
    "    # Declare counter\n",
    "    count = 1\n",
    "    \n",
    "    # Retrieve audio features of a trackId list\n",
    "    for trackId in track_id_list:\n",
    "        audio_features = get_audio_features(trackId)\n",
    "        if audio_features:\n",
    "            audio_features_dict[trackId] = audio_features # Create a dictionary with trackId as key and audio_features as value\n",
    "            print(f'track {count}: {trackId}...SUCCESSFUL')\n",
    "        else:\n",
    "            print(f'track {count}: {trackId}...FAILED')\n",
    "        count += 1\n",
    "            \n",
    "    # Transform dictionary into a list\n",
    "    audio_feature_list = []\n",
    "    for trackId, audio_features in audio_features_dict.items():\n",
    "        audio_feature_list.append({'trackId': trackId, **audio_features})\n",
    "        \n",
    "    # Transfrom list into a dataframe\n",
    "    audio_feature_df = pd.DataFrame(audio_feature_list)\n",
    "    audio_feature_df = audio_feature_df.drop(columns={'id','uri','track_href','analysis_url'})\n",
    "    \n",
    "    return audio_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to get the audio features\n",
    "track_id_list = track_reference_df['trackId'].unique().tolist()\n",
    "audio_feature_df = get_audio_features_df(track_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Get artist genre and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get artist info\n",
    "def get_artist_info_df(artist_id_list: list) -> dict:\n",
    "    # Create empty lists\n",
    "    artist_genre_list = []\n",
    "    artist_popularity_list = []\n",
    "    artist_follower_count_list = []\n",
    "    \n",
    "    # Declare a counter\n",
    "    count = 1\n",
    "    \n",
    "    # Retrieve artist info - Search by artistId\n",
    "    for artistId in artist_id_list:\n",
    "        try:\n",
    "            json = sp.artist(artistId)\n",
    "            print(f'artist {count}: {artistId}... SUCCESSFUL')\n",
    "        except Exception:\n",
    "            print(f'artist {count}: {artistId}... FAILED')\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            artist_genre_list.append(json['genres'][0]) # artist_genre, select the first entry\n",
    "        except Exception:\n",
    "            artist_genre_list.append('Unidentified')\n",
    "            \n",
    "        try:\n",
    "            artist_popularity_list.append(json['popularity']) # artist_popularity\n",
    "        except Exception:\n",
    "            artist_popularity_list.append('Unidentified')\n",
    "            \n",
    "        try:\n",
    "            artist_follower_count_list.append(json['followers']['total']) # artist_follower_count\n",
    "        except Exception:\n",
    "            artist_follower_count_list.append('Unidentified')\n",
    "            \n",
    "        count+=1\n",
    "        \n",
    "    \n",
    "    # Transform lists into a single dataframe\n",
    "    data_tuples = list(zip(artist_id_list, artist_genre_list, artist_popularity_list, artist_follower_count_list))\n",
    "    col_names = ['artistId','artistGenre', 'artistPopularity', 'artistFollowerCount']\n",
    "    df = pd.DataFrame(data_tuples, columns=col_names)\n",
    "    df = df.drop_duplicates().reset_index(drop=True)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to get the artist info\n",
    "artist_id_list = track_reference_df['artistId'].unique().tolist()\n",
    "artist_info_df = get_artist_info_df(artist_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Combine streaming history, track info, audio features, and artist info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to combine all dataframes, including track_reference_df, audio_feature_df, and artist_info_df\n",
    "def combine_dataframes():\n",
    "    df = streaming_hist_df.merge(track_reference_df, how='left', on=['trackName','artistName'])\n",
    "    df = df.merge(audio_feature_df, how='left', on=['trackId'])\n",
    "    df = df.merge(artist_info_df, how='left', on=['artistId'])\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to combine all dataframes\n",
    "spotify_df = combine_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Remove missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the percentage of null values in the dataframe\n",
    "def check_missing_values(df):\n",
    "    for index, value in df.items():\n",
    "        count_null = value.isnull()\n",
    "        percentage_null = count_null.sum() * 100.0 / np.shape(df)[0]\n",
    "        print(\"Percentage of null values in column %s = %.2f%%\" % (index, percentage_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to calculate the percentage of null values in the dataframe\n",
    "check_missing_values(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a funciton to remove rows with missing values\n",
    "def clean_spotify_df(df):\n",
    "    df = df[df['trackName'].notnull()]\n",
    "    df = df[df['trackId'].notnull()]\n",
    "    df = df[df['danceability'].notnull()]\n",
    "    df = df[df['artistGenre'].notnull()]\n",
    "    df = df.drop(columns={'username','episode_name','episode_show_name','spotify_episode_uri','skipped'})\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to remove rows with missing values\n",
    "spotify_df = clean_spotify_df(spotify_df)\n",
    "\n",
    "# Check again if there are still some missing values in the dataframe\n",
    "check_missing_values(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.7. Handling datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original data, we only have `ts`, representing the timestamp of when the stream ended in UTC format. Therefore, we will transform the data and add several fields to support our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to change ts from UTC to local time\n",
    "def convert_to_local_time(df, col):\n",
    "    # Create an empty list\n",
    "    clean_ts_local = []\n",
    "    \n",
    "    # Declare some date threshold\n",
    "    start_date = pd.Timestamp(pd.to_datetime('2021-09-04', format='%Y-%m-%d %H:%M:%S')).tz_localize('UTC')\n",
    "    end_date = pd.Timestamp(pd.to_datetime('2022-09-07', format='%Y-%m-%d %H:%M:%S')).tz_localize('UTC')\n",
    "    bst_date = pd.Timestamp(pd.to_datetime('2021-10-31', format='%Y-%m-%d %H:%M:%S')).tz_localize('UTC')\n",
    "    \n",
    "    # Convert to local time\n",
    "    for index, value in col.items():\n",
    "        datetime = pd.to_datetime(value, format='%Y-%m-%d %H:%M:%S')\n",
    "        if datetime < start_date or datetime > end_date: # When I lived in Jakarta\n",
    "            clean_ts_local.append(datetime + timedelta(hours=7))\n",
    "        elif datetime >= start_date and datetime < bst_date: # When I lived in the UK BST\n",
    "            clean_ts_local.append(datetime + timedelta(hours=1))\n",
    "        else:\n",
    "            clean_ts_local.append(datetime) # When I lived in the UK GMT\n",
    "        \n",
    "    # Append the result into a new column in the dataframe\n",
    "    df['ts_local'] = clean_ts_local\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to transform milisecons into seconds and minutes\n",
    "def transform_duration(df):\n",
    "    # Fill NA with 0\n",
    "    df[['ms_played', 'duration_ms']] = df[['ms_played','duration_ms']].fillna(value=0)\n",
    "    \n",
    "    # Create a column of duration in second\n",
    "    df['sec_played'] = df['ms_played']/1000\n",
    "    df['duration_sec'] = df['duration_ms']/1000\n",
    "    \n",
    "    # Create a column of duration in second\n",
    "    df['min_played'] = df['ms_played']/1000/60\n",
    "    df['duration_min'] = df['duration_ms']/1000.60\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to extract year, month, date, hour from the timestamp ts_local and albumReleaseDate\n",
    "def extract_year_month_date_hour(df):\n",
    "    # Step 1: Transform ts_local\n",
    "    # Create empty lists\n",
    "    year_ts_local = []\n",
    "    month_ts_local = []\n",
    "    date_ts_local = []\n",
    "    hour_ts_local = []\n",
    "    \n",
    "    # Extract year, year-month, year-month-date, and hour from the timestamp\n",
    "    for index, value in df['ts_local'].items():\n",
    "        year_ts_local.append(value.strftime('%Y'))\n",
    "        month_ts_local.append(value.strftime('%Y-%m'))\n",
    "        date_ts_local.append(value.strftime('%Y-%m-%d'))\n",
    "        hour_ts_local.append(value.strftime('%H'))\n",
    "        \n",
    "    # Append the results into new columns in the dataframe\n",
    "    df['year_ts_local'] = year_ts_local\n",
    "    df['month_ts_local'] = month_ts_local \n",
    "    df['date_ts_local'] = date_ts_local\n",
    "    df['hour_ts_local'] = hour_ts_local\n",
    "\n",
    "    # Step 2: Transform albumReleaseDate\n",
    "    # Create an empty list\n",
    "    release_year = []\n",
    "    \n",
    "    # Extract albumReleaseYear\n",
    "    for index, value in df['albumReleaseDate'].items():\n",
    "        try:\n",
    "            datetime = pd.to_datetime(value, format='%Y-%m-%d')\n",
    "            release_year.append(datetime.strftime('%Y'))\n",
    "        except Exception:\n",
    "            release_year.append('Unidentified')\n",
    "\n",
    "    # Append the result into a new column in the dataframe\n",
    "    df['albumReleaseYear'] = release_year\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to group the timestamps into its respective time category\n",
    "def append_time_category(df):\n",
    "    # Transform hour_ts_local into a list\n",
    "    hour_ts_local_list = df['hour_ts_local'].astype('int').to_list()\n",
    "    \n",
    "    # Create an empty list\n",
    "    time_cat_list = []\n",
    "    \n",
    "    # Write conditions to group the timestamps\n",
    "    for value in hour_ts_local_list:\n",
    "        if value >= 0 and value <= 5:\n",
    "            time_cat_list.append('00.00 - 05.59')\n",
    "        elif value >=6 and value <= 11:\n",
    "            time_cat_list.append('06.00 - 11.59')\n",
    "        elif value >= 12 and value <= 17:\n",
    "            time_cat_list.append('12.00 - 17.59')\n",
    "        elif value >= 18 and value <= 23:\n",
    "            time_cat_list.append('18.00 - 23.59')\n",
    "        else:\n",
    "            time_cat_list.append('Unidentified')\n",
    "    \n",
    "    # Append the result into a new column in the dataframe\n",
    "    df['ts_category'] = time_cat_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change endTime from UTC to local time\n",
    "spotify_df = convert_to_local_time(spotify_df, spotify_df['ts'])\n",
    "\n",
    "# Transform duration\n",
    "spotify_df = transform_duration(spotify_df)\n",
    "\n",
    "# Extract year, month, date, hour\n",
    "spotify_df = extract_year_month_date_hour(spotify_df)\n",
    "\n",
    "# Append time category\n",
    "spotify_df = append_time_category(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Time spent on Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to compute daily time spent on Spotify\n",
    "def daily_time_spent(df):\n",
    "    daily_plays = df.groupby(['year_ts_local','month_ts_local','date_ts_local'], as_index=False).agg({'sec_played':'sum'})\n",
    "    daily_plays['min_played'] = round(daily_plays['sec_played']/60,2)\n",
    "    daily_plays['hour_played'] = round(daily_plays['min_played']/60,2)\n",
    "    return daily_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to compute monthly time spent on Spotify\n",
    "def monthly_time_spent(df):\n",
    "    monthly_plays = df.groupby(['year_ts_local','month_ts_local'], as_index=False).agg({'sec_played':'sum'})\n",
    "    monthly_plays['min_played'] = round(monthly_plays['sec_played']/60,2)\n",
    "    monthly_plays['hour_played'] = round(monthly_plays['min_played']/60,2)\n",
    "    return monthly_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to compute yearly time spent on Spotify\n",
    "def yearly_time_spent(df):\n",
    "    yearly_plays = df.groupby('year_ts_local', as_index=False).agg({'sec_played':'sum'})\n",
    "    yearly_plays['min_played'] = round(yearly_plays['sec_played']/60,2)\n",
    "    yearly_plays['hour_played'] = round(yearly_plays['sec_played']/60,2)\n",
    "    return yearly_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily time spent on Spotify\n",
    "daily_time_spent(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute monthly time spent on Spotify\n",
    "monthly_time_spent(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute yearly time spent on Spotify\n",
    "yearly_time_spent(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Top tracks by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get top tracks by total minutes played\n",
    "# This following function retrieves the top 10 tracks of each year by total minutes played\n",
    "def top_tracks_by_year(df):\n",
    "    result_df = df.groupby(['year_ts_local','trackName','artistName','artistGenre','artistPopularity'], as_index=False).agg({'sec_played':'sum'})\n",
    "    result_df['min_played'] = round(result_df['sec_played']/60,2)\n",
    "    result_df = result_df.sort_values(['sec_played'], ascending=False).groupby('year_ts_local').head(10)\n",
    "    result_df = result_df.sort_values(['year_ts_local'],ascending=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get the top tracks\n",
    "top_tracks_by_year(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Top artists by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get top artists by total minutes played\n",
    "# This following function retrieves the top 10 artists of each year by total minutes played\n",
    "def top_artists_by_year(df):\n",
    "    result_df = df.groupby(['year_ts_local','artistId','artistName','artistGenre','artistPopularity'], as_index=False).agg({'sec_played':'sum','trackId':pd.Series.nunique})\n",
    "    result_df['min_played'] = round(result_df['sec_played']/60,2)    \n",
    "    result_df = result_df.rename(columns={'trackId':'unique_tracks'})\n",
    "    result_df = result_df.sort_values(['min_played'], ascending=False).groupby('year_ts_local').head(10)\n",
    "    result_df = result_df.sort_values(['year_ts_local','min_played'],ascending=False)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get the top artists\n",
    "top_artists_by_year(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. The days I discovered my favorite artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The day I discovered my top artists\n",
    "def the_day_I_discovered_my_favorite_artists(df):\n",
    "    # Write a function to get top artists by total minutes played\n",
    "    # This following function retrieves the top 10 artists of each year by total minutes played\n",
    "    result_df = df.groupby(['year_ts_local','artistId','artistName','artistGenre','artistPopularity'], as_index=False).agg({'sec_played':'sum','trackId':pd.Series.nunique})\n",
    "    result_df['min_played'] = round(result_df['sec_played']/60,2)    \n",
    "    result_df = result_df.rename(columns={'trackId':'unique_tracks'})\n",
    "    result_df = result_df.sort_values(['min_played'], ascending=False).groupby('year_ts_local').head(10)\n",
    "    result_df = result_df.sort_values(['year_ts_local','min_played'],ascending=False)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    \n",
    "    # Write a function to get the first date of listening\n",
    "    first_listen_df = df.groupby(['artistId'], as_index=False).agg({'date_ts_local':'min'})\n",
    "    first_listen_df = first_listen_df.rename(columns={'date_ts_local':'first_listen_date'})\n",
    "    \n",
    "    # Combine data\n",
    "    result_df = result_df.merge(first_listen_df, how='left', on=['artistId'])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_day_I_discovered_my_favorite_artists_df = the_day_I_discovered_my_favorite_artists(spotify_df)\n",
    "the_day_I_discovered_my_favorite_artists_df[the_day_I_discovered_my_favorite_artists_df['year_ts_local']=='2022']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Top genre by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get top genres by total minutes played\n",
    "# This following function retrieves the top 10 genres of each year by total minutes played\n",
    "def top_genre_by_year(df):\n",
    "    df = df[df['artistGenre']!='Unidentified']\n",
    "    result_df = df.groupby(['year_ts_local','artistGenre'], as_index=False).agg({'sec_played':'sum'})\n",
    "    result_df['min_played'] = round(result_df['sec_played']/60,2)\n",
    "    result_df = result_df.sort_values(['min_played'], ascending=False).groupby('year_ts_local').head(10)\n",
    "    result_df = result_df.sort_values(['year_ts_local','min_played'],ascending=False)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get the top genres\n",
    "top_genre_by_year(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. Most repeated songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get the most repeated song of each year\n",
    "def most_repeated_song_by_year(df):\n",
    "    # Sort the dataframe by the timestamp\n",
    "    df = df.sort_values('ts_local',ascending=True)\n",
    "    \n",
    "    # Retrieve the previously played track (Equivalent to LAG function in SQL)\n",
    "    df['previous_trackId'] = df['trackId'].shift(1)\n",
    "    \n",
    "    # Write a condition to flag whether the track being played is repeated or not\n",
    "    df['is_repeated'] = np.where(df['trackId']==df['previous_trackId'], 1, 0)\n",
    "    \n",
    "    # Compute the number of repeats with pd.Series.cumsum\n",
    "    df['count_repeated'] = df.groupby(['year_ts_local','date_ts_local','trackId','trackName','artistName','artistGenre'])['is_repeated'].transform(pd.Series.cumsum)\n",
    "    df = df.groupby(['year_ts_local','date_ts_local','trackId','trackName','artistName','artistGenre'],as_index=False).agg({'count_repeated':'max'}).sort_values('count_repeated',ascending=False)\n",
    "    \n",
    "    # Filter only the most repeated song for each year\n",
    "    df = df.loc[df.groupby('year_ts_local')['count_repeated'].idxmax()][['year_ts_local','trackId','trackName','artistName','artistGenre','count_repeated']].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get the most repeated song by year\n",
    "most_repeated_song_by_year(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get the most repeated songs by month (2022 only)\n",
    "def most_repeated_song_by_month(df):\n",
    "    # Filter to 2022 only and sort the dataframe by the timestamp\n",
    "    df = df[df['year_ts_local']=='2022'].reset_index(drop=True)\n",
    "    df = df.sort_values('ts_local',ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # Retrieve the previously played track (Equivalent to LAG function in SQL)    \n",
    "    df['previous_trackId'] = df['trackId'].shift(1)\n",
    "    \n",
    "    # Write a condition to flag whether the track being played is repeated or not    \n",
    "    df['is_repeated'] = np.where(df['trackId']==df['previous_trackId'], 1, 0)\n",
    "    \n",
    "    # Compute the number of repeats with pd.Series.cumsum\n",
    "    df['count_repeated'] = df.groupby(['month_ts_local','date_ts_local','trackId','trackName','artistName'])['is_repeated'].transform(pd.Series.cumsum)\n",
    "    df = df.groupby(['month_ts_local','date_ts_local','trackId','trackName','artistName'],as_index=False).agg({'count_repeated':'max'}).sort_values('count_repeated',ascending=False)\n",
    "    \n",
    "    # Filter only the most repeated song for each month in 2022\n",
    "    df = df.loc[df.groupby('month_ts_local')['count_repeated'].idxmax()][['month_ts_local','trackId','trackName','artistName','count_repeated']].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "most_repeated_song_by_month(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. Do I listen more to common or unique artists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to compute total minutes played by artistId as well as identify if an artist is Unique of Common\n",
    "def artistPopularity_min_played(df):\n",
    "    # Append a flag to identify whether an artist is unique or common\n",
    "    artistPopularity_list = df['artistPopularity'].astype('int').to_list()\n",
    "    artist_flag = []\n",
    "    for i in list(range(0,len(artistPopularity_list))):\n",
    "        if artistPopularity_list[i] <= 50:\n",
    "            artist_flag.append('Unique')\n",
    "        else:\n",
    "            artist_flag.append('Common')\n",
    "    \n",
    "    df['artistPopularityCat'] = artist_flag\n",
    "    \n",
    "    # Compute total minutes played by artistId\n",
    "    result_df = df.groupby(['artistId', 'artistName','artistGenre','artistPopularity', 'artistPopularityCat','year_ts_local'], as_index=False).agg({'sec_played':'sum','trackId':pd.Series.nunique})\n",
    "    result_df['min_played'] = round(result_df['sec_played']/60,2)\n",
    "    \n",
    "    # Rename columns for intuitiveness\n",
    "    result_df = result_df.rename(columns={'trackId':'unique_tracks'})\n",
    "    \n",
    "    # Remove uninformative entries\n",
    "    result_df = result_df[(result_df['sec_played']>0) & (result_df['unique_tracks']<=100)].reset_index(drop=True)\n",
    "    \n",
    "    # Sort by total minutes played\n",
    "    result_df = result_df.sort_values(['min_played'],ascending=False)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "unique_vs_common_artist_df = artistPopularity_min_played(spotify_df)\n",
    "\n",
    "# Aggregate the data\n",
    "unique_vs_common_artist_df = unique_vs_common_artist_df.groupby(['year_ts_local','artistPopularityCat'], as_index=False).agg({'sec_played':'sum', 'unique_tracks':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "unique_vs_common_artist_raw_df = artistPopularity_min_played(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8. Top genre by period of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_genre_by_time_category(df):\n",
    "    # Remove tracks with unidentified genre\n",
    "    df = df[df['artistGenre']!='Unidentified'].reset_index(drop=True)\n",
    "    \n",
    "    # Aggregate data\n",
    "    result_df = df.groupby(['year_ts_local','ts_category','artistGenre'], as_index=False).agg({'sec_played':'sum'})\n",
    "    result_df['min_played'] = round(result_df['sec_played']/60,2)\n",
    "    result_df = result_df.sort_values(['min_played'], ascending=False).groupby(['year_ts_local','ts_category']).head(5)\n",
    "    result_df = result_df.sort_values(['year_ts_local','ts_category'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get top genres by period of the day\n",
    "top_genre_by_time_cat_df = top_genre_by_time_category(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9. Audio features throughout the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_characteristics_throughout_the_day(df):\n",
    "    # Filter 2022 only\n",
    "    df = df[df['year_ts_local']=='2022'].reset_index(drop=True)\n",
    "    \n",
    "    # Aggregate data\n",
    "    result_df = df.groupby(['hour_ts_local'], as_index=False).agg({'danceability':'median',\n",
    "                                                                 'energy':'median',\n",
    "                                                                 'loudness':'median',\n",
    "                                                                 'speechiness':'median',\n",
    "                                                                 'acousticness':'median',\n",
    "                                                                 'liveness':'median',\n",
    "                                                                 'instrumentalness':'median',\n",
    "                                                                 'valence':'median',\n",
    "                                                                 'tempo':'median'})\n",
    "    \n",
    "    \n",
    "    result_df = pd.melt(result_df, id_vars=['hour_ts_local'], value_vars=['danceability','energy','loudness','speechiness','acousticness','instrumentalness','valence','tempo'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_char_throughout_the_day_df = audio_characteristics_throughout_the_day(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10. Songs I have a love-hate relationship with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to show tracks that appear in the top 100 but also frequently skipped\n",
    "def love_hate_songs(df):\n",
    "    # Filter 2022 only\n",
    "    df = df[df['year_ts_local']=='2022'].reset_index(drop=True)\n",
    "    \n",
    "    # Declare inputs\n",
    "    sec_played_list = df['sec_played'].to_list()\n",
    "    duration_sec = df['duration_sec'].to_list()\n",
    "    reason_end_list = df['reason_end'].to_list()\n",
    "    df_length = len(df)\n",
    "    pct_played_list = []\n",
    "    is_skipped_list = []\n",
    "    \n",
    "    for i in list(range(0,df_length)):\n",
    "        # Compute percentage of track played\n",
    "        pct_played = round(sec_played_list[i]/duration_sec[i],2)\n",
    "        pct_played_list.append(pct_played)\n",
    "        \n",
    "        # Add a flag to identify if a song is skipped\n",
    "        if reason_end_list[i] != 'trackdone':\n",
    "            is_skipped_list.append(1)\n",
    "        else:\n",
    "            is_skipped_list.append(0)   \n",
    "        \n",
    "    # Append the result to the dataframe\n",
    "    df['pct_played'] = pct_played_list\n",
    "    df['is_skipped'] = is_skipped_list\n",
    "    \n",
    "    # Get the number of skips by trackId\n",
    "    skipped_df = df.groupby(['trackId','trackName'], as_index=False).agg({'is_skipped':'sum'}).rename(columns={'is_skipped':'count_skipped'})\n",
    "    \n",
    "    # Get top 100 tracks in 2022 by number of played\n",
    "    top_100_tracks_df = df.groupby(['trackId','trackName'], as_index=False).size().rename(columns={'size':'count_played'})\n",
    "    top_100_tracks_df = top_100_tracks_df.sort_values(['count_played'], ascending=False).head(100)\n",
    "    \n",
    "    # Get love-hate songs (Appear in top 100 tracks but also frequently skipped)\n",
    "    love_hate_df = top_100_tracks_df.merge(skipped_df, how='left', on=['trackId','trackName'])\n",
    "    love_hate_df['pct_skipped'] = round(love_hate_df['count_skipped']/love_hate_df['count_played']*100,2)\n",
    "    love_hate_df = love_hate_df.sort_values('pct_skipped',ascending=False).head(10)\n",
    "    \n",
    "    return love_hate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "love_hate_songs_df = love_hate_songs(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11. Songs I love at the first listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def love_at_the_first_listen(df): \n",
    "    # first date of listening\n",
    "    first_listen_df = df.groupby(['trackId'], as_index=False).agg({'date_ts_local':'min'})\n",
    "    first_listen_df = first_listen_df.rename(columns={'date_ts_local':'first_listen_date'})\n",
    "    \n",
    "    # number of listening by date\n",
    "    daily_listen_df = df.groupby(['trackId','trackName','artistName','date_ts_local','year_ts_local'], as_index=False).size()\n",
    "    daily_listen_df = daily_listen_df.rename(columns={'size':'num_listen'})\n",
    "    \n",
    "    # count repeat by date\n",
    "    count_repeat_df = df.sort_values('ts_local',ascending=True)\n",
    "    count_repeat_df['previous_trackId'] = count_repeat_df['trackId'].shift(1)\n",
    "    count_repeat_df['is_repeated'] = np.where(count_repeat_df['trackId']==count_repeat_df['previous_trackId'], 1, 0)\n",
    "    count_repeat_df['count_repeated'] = count_repeat_df.groupby(['trackId','trackName','artistName','date_ts_local','year_ts_local'])['is_repeated'].transform(pd.Series.cumsum)\n",
    "    count_repeat_df = count_repeat_df.groupby(['trackId','trackName','artistName','date_ts_local','year_ts_local'],as_index=False).agg({'count_repeated':'max'})\n",
    "    \n",
    "    # combine dataframes\n",
    "    result_df = count_repeat_df.merge(first_listen_df, how='left', on='trackId')\n",
    "    result_df = result_df[result_df['first_listen_date']==result_df['date_ts_local']]\n",
    "    result_df = result_df.sort_values('count_repeated', ascending=False).head(50)\n",
    "\n",
    "    # filter 2022\n",
    "    result_df = result_df[result_df['year_ts_local']=='2022'].reset_index(drop=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_at_the_first_listen(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.12. Songs I skipped the first time but realized it was bomb much later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipped_first_repeated_later(df):\n",
    "    # Count percentage played (ms_played/duration_ms)\n",
    "    pct_played_df = df[['trackId','ts_local','ms_played','duration_ms']].reset_index(drop=True)\n",
    "    pct_played_df['pct_played'] = round(pct_played_df['ms_played']/pct_played_df['duration_ms']*100,2)\n",
    "    \n",
    "    # Extract first listen timestamp\n",
    "    first_listen_df = df.groupby(['trackId'], as_index=False).agg({'ts_local':'min'})\n",
    "    first_listen_df = first_listen_df.merge(pct_played_df, how='inner', on=['trackId','ts_local'])\n",
    "    \n",
    "    # Extract songs that I skipped at the first listen\n",
    "    reason_end_list = ['endplay','fwdbtn','backbtn']\n",
    "    df_filtered = df[['trackId','trackName','artistName','ts_local','reason_end']]\n",
    "    skipped_first_listen_df = first_listen_df.merge(df_filtered, how='inner', on=['trackId','ts_local'])\n",
    "    skipped_first_listen_df = skipped_first_listen_df[skipped_first_listen_df['reason_end'].isin(reason_end_list)][['trackId','trackName','artistName','ts_local','reason_end','ms_played','duration_ms','pct_played']]\n",
    "    skipped_first_listen_df = skipped_first_listen_df.rename(columns={'ts_local':'first_listen_ts_local'})\n",
    "    \n",
    "    # Extract date from first_listen_ts_local\n",
    "    first_listen_date_ts_local = []\n",
    "    for index, value in skipped_first_listen_df['first_listen_ts_local'].items():\n",
    "         first_listen_date_ts_local.append(value.strftime('%Y-%m-%d'))\n",
    "    skipped_first_listen_df['first_listen_date_ts_local'] =  first_listen_date_ts_local\n",
    "       \n",
    "    # Count repeat, grouped by date\n",
    "    count_repeat_df = df.sort_values('ts_local',ascending=True)\n",
    "    count_repeat_df['previous_trackId'] = count_repeat_df['trackId'].shift(1)\n",
    "    count_repeat_df['is_repeated'] = np.where(count_repeat_df['trackId']==count_repeat_df['previous_trackId'], 1, 0)\n",
    "    count_repeat_df['count_repeated'] = count_repeat_df.groupby(['trackId','trackName','artistName','date_ts_local','year_ts_local'])['is_repeated'].transform(pd.Series.cumsum)\n",
    "    count_repeat_df = count_repeat_df.groupby(['trackId','trackName','artistName','date_ts_local','year_ts_local'],as_index=False).agg({'count_repeated':'max'})\n",
    "    count_repeat_df['rank'] = count_repeat_df.groupby(['trackId','trackName','artistName'])['count_repeated'].rank(ascending=False)\n",
    "    count_repeat_df = count_repeat_df[count_repeat_df['rank']==1].reset_index(drop=True)\n",
    "    \n",
    "    # Combine dataframe\n",
    "    result_df = count_repeat_df.merge(skipped_first_listen_df, how='inner', on=['trackId','trackName','artistName'])\n",
    "    result_df = result_df.sort_values('count_repeated',ascending=False)\n",
    "    \n",
    "    # Rearrange dataframe\n",
    "    result_df = result_df[['trackId','trackName','artistName','first_listen_date_ts_local','date_ts_local','year_ts_local','count_repeated','reason_end','ms_played','duration_ms','pct_played']]\n",
    "    result_df = result_df[result_df['pct_played']<100]\n",
    "    \n",
    "    # Filter top 10\n",
    "    result_df = result_df[result_df['year_ts_local']=='2022'].head(10).reset_index(drop=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_first_repeated_later(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.13. Do I tend to be more explorative over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_new_artists_by_year(df):    \n",
    "    # Extract first listen timestamp\n",
    "    first_listen_df = df.groupby(['artistId'], as_index=False).agg({'ts_local':'min'})\n",
    "    first_listen_df = first_listen_df.rename(columns={'ts_local':'first_listen_ts_local'})\n",
    "    \n",
    "    # Extract year from first_listen_ts_local\n",
    "    first_listen_year_ts_local = []\n",
    "    for index, value in first_listen_df['first_listen_ts_local'].items():\n",
    "         first_listen_year_ts_local.append(value.strftime('%Y'))\n",
    "    first_listen_df['first_listen_year_ts_local'] =  first_listen_year_ts_local\n",
    "    \n",
    "    # Combine dataframe\n",
    "    result_df = df.merge(first_listen_df, how='left', on=['artistId']).reset_index(drop=True)\n",
    "    \n",
    "    # Append new artist flag\n",
    "    first_listen_year_list = result_df['first_listen_year_ts_local'].to_list()\n",
    "    year_played_list = result_df['year_ts_local'].to_list()\n",
    "    \n",
    "    new_artist_flag = []\n",
    "    for i in list(range(0, len(result_df))):\n",
    "        if first_listen_year_list[i] == year_played_list[i]:\n",
    "            new_artist_flag.append('New artist')\n",
    "        else:\n",
    "            new_artist_flag.append('Familiar artist')\n",
    "            \n",
    "    result_df['new_artist_flag'] = new_artist_flag\n",
    "    \n",
    "    # Count total unique artists by year\n",
    "    unique_artist_df = result_df.groupby(['year_ts_local'],as_index=False).agg({'artistId':pd.Series.nunique})\n",
    "    unique_artist_df = unique_artist_df.rename(columns={'artistId':'unique_artists'})\n",
    "    \n",
    "    # Count new artists by year\n",
    "    new_artist_df = result_df.groupby(['year_ts_local','new_artist_flag'], as_index=False).agg({'artistId':pd.Series.nunique})\n",
    "    #new_artist_df = new_artist_df.pivot(index='year_ts_local', columns='new_artist_flag', values='artistId').reset_index(drop=False)\n",
    "    #new_artist_df = new_artist_df[['year_ts_local','True']].rename(columns={'True':'unique_new_artists'})\n",
    "    \n",
    "    # Combine dataframes\n",
    "    #final_df = unique_artist_df.merge(new_artist_df, how='left', on=['year_ts_local'])\n",
    "    #final_df['pct_new_artists'] = round(final_df['unique_new_artists']/final_df['unique_artists']*100,2)\n",
    "    \n",
    "    return new_artist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pct_new_artists_by_year(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_new_tracks_by_year(df):    \n",
    "    # Extract first listen timestamp\n",
    "    first_listen_df = df.groupby(['trackId'], as_index=False).agg({'ts_local':'min'})\n",
    "    first_listen_df = first_listen_df.rename(columns={'ts_local':'first_listen_ts_local'})\n",
    "    \n",
    "    # Extract year from first_listen_ts_local\n",
    "    first_listen_year_ts_local = []\n",
    "    for index, value in first_listen_df['first_listen_ts_local'].items():\n",
    "         first_listen_year_ts_local.append(value.strftime('%Y'))\n",
    "    first_listen_df['first_listen_year_ts_local'] =  first_listen_year_ts_local\n",
    "    \n",
    "    # Combine dataframe\n",
    "    result_df = df.merge(first_listen_df, how='left', on=['trackId']).reset_index(drop=True)\n",
    "    \n",
    "    # Append new artist flag\n",
    "    first_listen_year_list = result_df['first_listen_year_ts_local'].to_list()\n",
    "    year_played_list = result_df['year_ts_local'].to_list()\n",
    "    \n",
    "    new_track_flag = []\n",
    "    for i in list(range(0, len(result_df))):\n",
    "        if first_listen_year_list[i] == year_played_list[i]:\n",
    "            new_track_flag.append('New track')\n",
    "        else:\n",
    "            new_track_flag.append('Familiar track')\n",
    "            \n",
    "    result_df['new_track_flag'] = new_track_flag\n",
    "    \n",
    "    # Count total unique tracks by year\n",
    "    unique_track_df = result_df.groupby(['year_ts_local'],as_index=False).agg({'trackId':pd.Series.nunique})\n",
    "    unique_track_df = unique_track_df.rename(columns={'trackId':'unique_tracks'})\n",
    "    \n",
    "    # Count new tracks by year\n",
    "    new_track_df = result_df.groupby(['year_ts_local','new_track_flag'], as_index=False).agg({'trackId':pd.Series.nunique})\n",
    "    #new_track_df = new_track_df.pivot(index='year_ts_local', columns='new_track_flag', values='trackId').reset_index(drop=False)\n",
    "    #new_track_df = new_track_df[['year_ts_local','True']].rename(columns={'True':'unique_new_tracks'})\n",
    "    \n",
    "    # Combine dataframes\n",
    "    #final_df = unique_track_df.merge(new_track_df, how='left', on=['year_ts_local'])\n",
    "    #final_df['pct_new_tracks'] = round(final_df['unique_new_tracks']/final_df['unique_tracks']*100,2)\n",
    "    \n",
    "    return new_track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_new_tracks_by_year(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.14. Songs I no longer love as much as I did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def songs_I_dont_love_anymore(df):\n",
    "    # Filter year\n",
    "    df = df[df['year_ts_local'].isin(['2021','2022'])].reset_index(drop=True)\n",
    "    \n",
    "    # Total ms played\n",
    "    total_ms_played_df = df.groupby(['year_ts_local'], as_index=False).agg({'ms_played':'sum'})\n",
    "    total_ms_played_2021 = total_ms_played_df[total_ms_played_df['year_ts_local']=='2021']['ms_played'][0]\n",
    "    total_ms_played_2022 = total_ms_played_df[total_ms_played_df['year_ts_local']=='2022']['ms_played'][1]\n",
    "    overall_pct_growth = round(((total_ms_played_2022/total_ms_played_2021)-1)*100,2)\n",
    "    \n",
    "    result_df = df.groupby(['trackId','year_ts_local'], as_index=False).agg({'ms_played':'sum'})\n",
    "    result_df = result_df.pivot(index='trackId', columns='year_ts_local', values='ms_played').reset_index(drop=False)\n",
    "    result_df = result_df[(result_df['2021'].notnull()) & (result_df['2022'].notnull())]\n",
    "    result_df = result_df.sort_values('2021', ascending=False).head(50).reset_index(drop=True)\n",
    "    result_df['pct_growth'] = round(((result_df['2022']/result_df['2021'])-1)*100,2)\n",
    "    \n",
    "    # Filter\n",
    "    result_df = result_df[result_df['pct_growth']<overall_pct_growth]\n",
    "    \n",
    "    # Append trackName and artistName\n",
    "    result_df = result_df.merge(track_reference_df[['trackId','trackName','artistName']], how='left', on=['trackId'])\n",
    "    result_df['rank'] = result_df.groupby(['trackId'])['pct_growth'].rank(ascending=False)\n",
    "    result_df = result_df[result_df['rank']==1].drop(columns={'rank'})\n",
    "    result_df = result_df.sort_values(['pct_growth'], ascending=True).head(10)\n",
    "    \n",
    "    result_df = pd.melt(result_df, id_vars=['trackId','trackName','artistName','pct_growth'], value_vars=['2021','2022'])\n",
    "    result_df = result_df.rename(columns={'variable':'year', 'value':'ms_played'})\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_I_dont_love_anymore(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.15. Songs from the past that I am still listening today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to show tracks that appear in the top 100 and released more than 30 years ago\n",
    "def songs_from_the_past(df):\n",
    "    # Filter 2022 only\n",
    "    df = df[df['year_ts_local']=='2022'].reset_index(drop=True)\n",
    "    \n",
    "    # Get top 100 tracks in 2022 by number of played\n",
    "    top_100_tracks_df = df.groupby(['trackId','trackName'], as_index=False).size().rename(columns={'size':'count_played'})\n",
    "    top_100_tracks_df = top_100_tracks_df.sort_values(['count_played'], ascending=False).head(100)\n",
    "    \n",
    "    # Get the old souls in me\n",
    "    old_songs_df = df[df['albumReleaseYear']<='1992'][['trackId','trackName','artistName','albumReleaseYear']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    old_songs_df = old_songs_df.merge(top_100_tracks_df, how='inner', on=['trackId','trackName'])\n",
    "\n",
    "    return old_songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_from_the_past(spotify_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
